{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c80a2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from setup_nb_env import *\n",
    "\n",
    "from epsampling.utils import load_csv\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "from epsampling.utils import drop_sers_with_nans\n",
    "from epsampling.utils import date_str_to_int\n",
    "\n",
    "DATA_DIR = '/work/users/k/4/k4thryn/Repos/EpSampling/data/'\n",
    "DT = datetime.today().strftime('%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407eb74",
   "metadata": {},
   "source": [
    "### NOTE: Need to run this all at once, cannot re-run cells due to reuse of \"df\" variable name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cca7af",
   "metadata": {},
   "source": [
    "### <font color=blue> CovidHub ensemble state predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d5eab3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56474e4c83ed4003ba6b24381fb479a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped cols with NaNs!\n",
      "Num cols before: 7\n",
      "Num cols after: 6\n",
      "20241009-144131\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "## COVID HUB ENSEMBLE STATE PREDICTIONS ############\n",
    "#####################################################\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "my_dir = os.path.join(DATA_DIR,'raw','COVIDhub-ensemble')\n",
    "files = glob.glob(f'{my_dir}/*.csv')\n",
    "\n",
    "types = ['point']\n",
    "targets = ['1 wk ahead inc death']\n",
    "\n",
    "all_dfs = []\n",
    "for f in tqdm(files,total=len(files)):\n",
    "    df = pd.read_csv(f)\n",
    "    ## Choose which types (only point for now)\n",
    "    df = df[df.type=='point']\n",
    "    ## Only 1 wk ahead inc\n",
    "    df = df[df.target.isin(targets)]\n",
    "    all_dfs.append(df)\n",
    "df_all = pd.concat(all_dfs)\n",
    "# df_all.sort_values(['Fips','Date'], inplace=True)\n",
    "df_all.reset_index(drop=True,inplace=True)\n",
    "# display(df_all)\n",
    "\n",
    "## check for nans\n",
    "df = drop_sers_with_nans(df_all, from_axis='cols')\n",
    "\n",
    "## REFORMAT dataframe ...\n",
    "## rename cols\n",
    "df.rename({'location':'State_fips',\n",
    "           'target_end_date':'Date',\n",
    "           'value':'Proj_inc_deaths'}, axis=1, inplace=True)\n",
    "## choose cols\n",
    "df = df[['State_fips','Date','Proj_inc_deaths']]\n",
    "\n",
    "## IMPORTANT: choose only state fips\n",
    "df = df[df.State_fips!='US']\n",
    "\n",
    "## convert all cols to numerical\n",
    "df['State_fips'] = df.State_fips.astype(int)\n",
    "df['Date'] = df.Date.apply(lambda x: date_str_to_int(x))\n",
    "\n",
    "## reset index\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "## SAVE CSV!\n",
    "# fpath = os.path.join(DATA_DIR,'processed','scratch',f'formatted_COVIDhub-ensemble_{DT}.csv')\n",
    "fpath = os.path.join(DATA_DIR,'processed',f'formatted_COVIDhub-ensemble_{DT}.csv')\n",
    "df.to_csv(fpath,index=False)\n",
    "print(DT)\n",
    "\n",
    "## READ BACK AND CHECK\n",
    "dff = pd.read_csv(fpath)\n",
    "# display(df, dff)\n",
    "# dff.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273083e6",
   "metadata": {},
   "source": [
    "### <font color=blue> NYTimes true county deaths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0804224c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped rows with NaNs!\n",
      "Num rows before: 2502832\n",
      "Num rows after: 2421549\n",
      "20241009-144131\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "## NYT TRUE COUNTY DEATHS ###########################\n",
    "#####################################################\n",
    "\n",
    "fpath = os.path.join(DATA_DIR,'raw','nytimes','us-counties.csv')\n",
    "df = pd.read_csv(fpath)\n",
    "\n",
    "## check for rows with nans. \n",
    "# display(df)\n",
    "df = drop_sers_with_nans(df, from_axis='rows')\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# display(df)\n",
    "\n",
    "## REFORMAT dataframe ...\n",
    "## capitalize cols.\n",
    "df.columns = df.columns.str.capitalize()\n",
    "## rename cols\n",
    "df.rename({'Deaths':'True_cum_deaths'},axis=1,inplace=True)\n",
    "## choose cols\n",
    "df = df[['Fips','Date', 'True_cum_deaths']]\n",
    "\n",
    "## convert all cols to numerical\n",
    "df['Fips'] = df.Fips.astype(int)\n",
    "df['Date'] = df.Date.apply(lambda x: date_str_to_int(x))\n",
    "\n",
    "## IMPORTANT: pull out samples from 'nytimes' that have matched dates to 'COVIDhub-ensemble' ...\n",
    "df_hub,_ = load_csv('formatted_COVIDhub-ensemble')\n",
    "my_dates = df_hub.Date.unique().tolist()\n",
    "df = df[df.Date.isin(my_dates)]\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "## reset index\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "## SAVE CSV!\n",
    "# fpath = os.path.join(DATA_DIR,'processed','scratch',f'formatted_nytimes-us-counties_{DT}.csv')\n",
    "fpath = os.path.join(DATA_DIR,'processed',f'formatted_nytimes-us-counties_{DT}.csv')\n",
    "df.to_csv(fpath,index=False)\n",
    "print(DT)\n",
    "\n",
    "## READ BACK AND CHECK\n",
    "dff = pd.read_csv(fpath)\n",
    "# display(df, dff)\n",
    "# dff.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d44f19",
   "metadata": {},
   "source": [
    "# <font color=blue> ACS RESULTS _(normed)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25466a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped cols with NaNs!\n",
      "Num cols before: 189\n",
      "Num cols after: 188\n",
      "20241009-144131\n"
     ]
    }
   ],
   "source": [
    "# problem dfs:\n",
    "# XX_blockgroup_acs5_2021_healthinsurance.csv\n",
    "# XX_blockgroup_acs5_2021_income.csv\n",
    "\n",
    "def normalize_attrs_by_pop(df, f):\n",
    "    f = (f[f.rindex('/')+1:-4])\n",
    "    f = f[f.rindex('_')+1:]\n",
    "    \n",
    "    df.set_index('GEOID',drop=True,inplace=True)\n",
    "\n",
    "    if f=='healthinsurance':\n",
    "        df['HINS_A0018'] = df['HINS_A0018'].div(df['POP_A0018'])\n",
    "        df['HINS_A1934'] = df['HINS_A1934'].div(df['POP_A1934'])\n",
    "        df['HINS_A3564'] = df['HINS_A3564'].div(df['POP_A3564'])\n",
    "        df['HINS_A65p'] = df['HINS_A65p'].div(df['POP_A65p'])\n",
    "        \n",
    "        dff = df.drop(['POP_A0018','POP_A1934','POP_A1934','POP_A65p'],inplace=False,axis=1)\n",
    "        \n",
    "    elif f=='income':\n",
    "        denom = df['HH']\n",
    "        \n",
    "        dff = df.apply(lambda x: x/denom, axis=0) \n",
    "        ## fix MHI since its not supposed to be normalized\n",
    "        dff['MHI'] = df['MHI']\n",
    "        dff['HH'] = denom\n",
    "\n",
    "    else:\n",
    "        universe = df.columns[0]\n",
    "        denom = df[universe]\n",
    "        \n",
    "        dff = df.apply(lambda x: x/denom, axis=0)\n",
    "        dff[universe] = denom\n",
    "        \n",
    "    dff = dff.reset_index(inplace=False, drop=False)\n",
    "    return dff\n",
    "\n",
    "def get_state_df(files):\n",
    "    first_df = None\n",
    "    for i,f in enumerate(files):\n",
    "        this_df = pd.read_csv(f)\n",
    "        this_df = normalize_attrs_by_pop(this_df, f)\n",
    "        if first_df is None:\n",
    "            first_df = this_df\n",
    "        else:\n",
    "            df = pd.merge(first_df, this_df, on='GEOID', suffixes=(f'_x{i}', f'_x{i+1}'))\n",
    "            first_df = df\n",
    "    return df\n",
    "\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "acs_dir = '/work/users/k/4/k4thryn/Repos/EpSampling/data/raw/acs_results/'\n",
    "\n",
    "all_st_dfs = []\n",
    "\n",
    "state_dirs = [x for x in os.walk(acs_dir)][0][1]\n",
    "\n",
    "for i,state in enumerate(state_dirs):\n",
    "    if i==0:\n",
    "        continue    \n",
    "        \n",
    "    files = glob.glob(f'{acs_dir}{state}/*.csv')\n",
    "    df = get_state_df(files)\n",
    "    ## REFORMAT dataframe ... rename cols.\n",
    "    df.rename({'GEOID':'Fips'},axis=1,inplace=True)\n",
    "    all_st_dfs.append(df)\n",
    "    \n",
    "df = pd.concat(all_st_dfs)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "## check for cols with nans.\n",
    "df = drop_sers_with_nans(df, from_axis='cols')\n",
    "\n",
    "## reset index\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "## SAVE CSV!\n",
    "# fpath = os.path.join(DATA_DIR,'processed','scratch',f'formatted_acs_results_{DT}.csv')\n",
    "fpath = os.path.join(DATA_DIR,'processed',f'formatted_acs_results_normed_{DT}.csv')\n",
    "df.to_csv(fpath,index=False)\n",
    "print(DT)\n",
    "\n",
    "## READ BACK AND CHECK\n",
    "# dff = pd.read_csv(fpath)\n",
    "# display(df, dff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d373d276",
   "metadata": {},
   "source": [
    "### <font color=blue> Add pop ratio to ACS and dedup identical covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0053afcd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20241009-144131\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fips</th>\n",
       "      <th>Pop</th>\n",
       "      <th>State_fips</th>\n",
       "      <th>State_pop</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>POP_NHPINH</th>\n",
       "      <th>POP_NHPI</th>\n",
       "      <th>POP_AIANNH</th>\n",
       "      <th>POP_AIAN</th>\n",
       "      <th>IND_AFFHM_MQE</th>\n",
       "      <th>...</th>\n",
       "      <th>HINS_A3564</th>\n",
       "      <th>HU_OCC</th>\n",
       "      <th>POP_NH</th>\n",
       "      <th>HINS_A0018</th>\n",
       "      <th>HINS_A65p</th>\n",
       "      <th>HH_x5</th>\n",
       "      <th>POP_A3564</th>\n",
       "      <th>HU_x14</th>\n",
       "      <th>POP_16p_EMP_x7</th>\n",
       "      <th>POP_A25p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001.000</td>\n",
       "      <td>58239.000</td>\n",
       "      <td>1</td>\n",
       "      <td>4997675</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.998</td>\n",
       "      <td>21856.000</td>\n",
       "      <td>22690.000</td>\n",
       "      <td>24170.000</td>\n",
       "      <td>25871.000</td>\n",
       "      <td>39614.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003.000</td>\n",
       "      <td>227131.000</td>\n",
       "      <td>1</td>\n",
       "      <td>4997675</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.992</td>\n",
       "      <td>87190.000</td>\n",
       "      <td>89031.000</td>\n",
       "      <td>121763.000</td>\n",
       "      <td>104367.000</td>\n",
       "      <td>161977.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005.000</td>\n",
       "      <td>25259.000</td>\n",
       "      <td>1</td>\n",
       "      <td>4997675</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.999</td>\n",
       "      <td>9088.000</td>\n",
       "      <td>7823.000</td>\n",
       "      <td>11667.000</td>\n",
       "      <td>8561.000</td>\n",
       "      <td>17995.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007.000</td>\n",
       "      <td>22412.000</td>\n",
       "      <td>1</td>\n",
       "      <td>4997675</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7083.000</td>\n",
       "      <td>8347.000</td>\n",
       "      <td>9013.000</td>\n",
       "      <td>8223.000</td>\n",
       "      <td>16057.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009.000</td>\n",
       "      <td>58884.000</td>\n",
       "      <td>1</td>\n",
       "      <td>4997675</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.998</td>\n",
       "      <td>21300.000</td>\n",
       "      <td>22918.000</td>\n",
       "      <td>24527.000</td>\n",
       "      <td>24244.000</td>\n",
       "      <td>40668.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>56037.000</td>\n",
       "      <td>42459.000</td>\n",
       "      <td>56</td>\n",
       "      <td>576641</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.903</td>\n",
       "      <td>1.000</td>\n",
       "      <td>15529.000</td>\n",
       "      <td>16838.000</td>\n",
       "      <td>19174.000</td>\n",
       "      <td>20884.000</td>\n",
       "      <td>27816.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>56039.000</td>\n",
       "      <td>23319.000</td>\n",
       "      <td>56</td>\n",
       "      <td>576641</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.892</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9531.000</td>\n",
       "      <td>9875.000</td>\n",
       "      <td>13255.000</td>\n",
       "      <td>14952.000</td>\n",
       "      <td>17659.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>56041.000</td>\n",
       "      <td>20514.000</td>\n",
       "      <td>56</td>\n",
       "      <td>576641</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.994</td>\n",
       "      <td>7675.000</td>\n",
       "      <td>7709.000</td>\n",
       "      <td>8819.000</td>\n",
       "      <td>9688.000</td>\n",
       "      <td>13233.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>56043.000</td>\n",
       "      <td>7768.000</td>\n",
       "      <td>56</td>\n",
       "      <td>576641</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.986</td>\n",
       "      <td>3370.000</td>\n",
       "      <td>2958.000</td>\n",
       "      <td>3842.000</td>\n",
       "      <td>3907.000</td>\n",
       "      <td>5423.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>56045.000</td>\n",
       "      <td>6891.000</td>\n",
       "      <td>56</td>\n",
       "      <td>576641</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.845</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2754.000</td>\n",
       "      <td>2724.000</td>\n",
       "      <td>3431.000</td>\n",
       "      <td>3044.000</td>\n",
       "      <td>4892.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3112 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Fips        Pop  State_fips  State_pop  Ratio  POP_NHPINH  POP_NHPI  \\\n",
       "0     1001.000  58239.000           1    4997675  0.012       0.000     0.000   \n",
       "1     1003.000 227131.000           1    4997675  0.045       0.000     0.000   \n",
       "2     1005.000  25259.000           1    4997675  0.005       0.000     0.000   \n",
       "3     1007.000  22412.000           1    4997675  0.004       0.000     0.000   \n",
       "4     1009.000  58884.000           1    4997675  0.012       0.001     0.001   \n",
       "...        ...        ...         ...        ...    ...         ...       ...   \n",
       "3107 56037.000  42459.000          56     576641  0.074       0.000     0.001   \n",
       "3108 56039.000  23319.000          56     576641  0.040       0.001     0.001   \n",
       "3109 56041.000  20514.000          56     576641  0.036       0.000     0.000   \n",
       "3110 56043.000   7768.000          56     576641  0.013       0.000     0.000   \n",
       "3111 56045.000   6891.000          56     576641  0.012       0.010     0.011   \n",
       "\n",
       "      POP_AIANNH  POP_AIAN  IND_AFFHM_MQE  ...  HINS_A3564  HU_OCC  POP_NH  \\\n",
       "0          0.002     0.002          0.002  ...       0.898   0.904   0.970   \n",
       "1          0.005     0.006          0.002  ...       0.885   0.716   0.953   \n",
       "2          0.003     0.003          0.000  ...       0.868   0.779   0.953   \n",
       "3          0.001     0.001          0.022  ...       0.870   0.786   0.972   \n",
       "4          0.001     0.003          0.004  ...       0.860   0.868   0.905   \n",
       "...          ...       ...            ...  ...         ...     ...     ...   \n",
       "3107       0.011     0.012          0.150  ...       0.853   0.810   0.839   \n",
       "3108       0.001     0.001          0.004  ...       0.893   0.719   0.851   \n",
       "3109       0.001     0.003          0.077  ...       0.853   0.870   0.903   \n",
       "3110       0.005     0.009          0.027  ...       0.815   0.877   0.856   \n",
       "3111       0.013     0.013          0.188  ...       0.863   0.803   0.981   \n",
       "\n",
       "      HINS_A0018  HINS_A65p     HH_x5  POP_A3564     HU_x14  POP_16p_EMP_x7  \\\n",
       "0          0.979      0.998 21856.000  22690.000  24170.000       25871.000   \n",
       "1          0.941      0.992 87190.000  89031.000 121763.000      104367.000   \n",
       "2          0.972      0.999  9088.000   7823.000  11667.000        8561.000   \n",
       "3          0.980      1.000  7083.000   8347.000   9013.000        8223.000   \n",
       "4          0.966      0.998 21300.000  22918.000  24527.000       24244.000   \n",
       "...          ...        ...       ...        ...        ...             ...   \n",
       "3107       0.903      1.000 15529.000  16838.000  19174.000       20884.000   \n",
       "3108       0.892      1.000  9531.000   9875.000  13255.000       14952.000   \n",
       "3109       0.932      0.994  7675.000   7709.000   8819.000        9688.000   \n",
       "3110       0.971      0.986  3370.000   2958.000   3842.000        3907.000   \n",
       "3111       0.845      1.000  2754.000   2724.000   3431.000        3044.000   \n",
       "\n",
       "       POP_A25p  \n",
       "0     39614.000  \n",
       "1    161977.000  \n",
       "2     17995.000  \n",
       "3     16057.000  \n",
       "4     40668.000  \n",
       "...         ...  \n",
       "3107  27816.000  \n",
       "3108  17659.000  \n",
       "3109  13233.000  \n",
       "3110   5423.000  \n",
       "3111   4892.000  \n",
       "\n",
       "[3112 rows x 162 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from epsampling.utils import drop_duplicate_cols\n",
    "\n",
    "## Remove duplicate columns\n",
    "df = drop_duplicate_cols(df)\n",
    "\n",
    "## Rename cols\n",
    "df.rename({'POP_x2':'Pop'},axis=1,inplace=True)\n",
    "## Reorder columns\n",
    "df = df[['Fips','Pop'] + [c for c in df.columns if c not in ['Fips','Pop']]]\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # #\n",
    "## Get county ratios and insert state pop, state fips, and county ratio cols.\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "df.insert(2, 'State_fips', 0)\n",
    "df.insert(3, 'State_pop',0)\n",
    "df.insert(4, 'Ratio', 0)\n",
    "\n",
    "for tup in df.itertuples():\n",
    "    \n",
    "    state_fips = tup.Fips // 1000\n",
    "    df.at[tup.Index, 'State_fips'] = state_fips    \n",
    "\n",
    "for tup in df.itertuples():\n",
    "    \n",
    "    state_pop = sum(df[df.State_fips==tup.State_fips].Pop)\n",
    "    ratio = tup.Pop / state_pop\n",
    "    \n",
    "    df.at[tup.Index, 'State_pop'] = state_pop\n",
    "    df.at[tup.Index, 'Ratio'] = ratio\n",
    "    \n",
    "## reset cols\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "## SAVE CSV!\n",
    "# fpath = os.path.join(DATA_DIR,'processed','scratch',f'formatted_acs_pop_ratio_{DT}.csv')\n",
    "fpath = os.path.join(DATA_DIR,'processed',f'formatted_acs_normed_pop_ratio_{DT}.csv')\n",
    "df.to_csv(fpath,index=False)\n",
    "print(DT)\n",
    "\n",
    "## READ BACK AND CHECK\n",
    "dff = pd.read_csv(fpath)\n",
    "display(dff)\n",
    "# dff.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c46ffb",
   "metadata": {},
   "source": [
    "# <font color=blue> TARGET PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b0228c",
   "metadata": {},
   "source": [
    "### <font color=blue> Compute GROUND TRUTH incident deaths for nyt county-level dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32d665af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa6787cd0074f3a8600005a3cf0d782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpath = os.path.join(DATA_DIR,'processed',f'formatted_nytimes-us-counties_{DT}.csv')\n",
    "df_nyt = pd.read_csv(fpath)\n",
    "\n",
    "## Compute inc deaths as (cum deaths) at t minus (cum deaths) at t-1 ...\n",
    "## keep nans and negatives !!\n",
    "\n",
    "df_nyt = df_nyt.sort_values(['Fips','Date'])\n",
    "\n",
    "dfs = []\n",
    "for fips in tqdm(df_nyt.Fips.unique()):\n",
    "    \n",
    "    df_county = df_nyt[df_nyt.Fips==fips]\n",
    "    df_county.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    inc_deathss = []\n",
    "    for i in range(len(df_county)):\n",
    "        if i==0:\n",
    "            inc_deaths = np.nan\n",
    "        else:          \n",
    "#             inc_deaths = df_county.True_cum_deaths.values[i] - df_county.True_cum_deaths.values[i-1]\n",
    "            inc_deaths = df_county.at[i,'True_cum_deaths'] - df_county.at[i-1,'True_cum_deaths']   \n",
    "        inc_deathss.append(inc_deaths)\n",
    "            \n",
    "    df_county['True_inc_deaths'] = inc_deathss\n",
    "    dfs.append(df_county)\n",
    "    \n",
    "df_tot = pd.concat(dfs)\n",
    "# df_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f988f5",
   "metadata": {},
   "source": [
    "### <font color=blue> Add necessary columns (for naive death computation) from acs and hub to main (nyt) dataframe. Do naive death computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c20daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATA_DIR,'processed',f'formatted_acs_normed_pop_ratio_{DT}.csv')\n",
    "df_acs = pd.read_csv(fpath)\n",
    "fpath = os.path.join(DATA_DIR,'processed',f'formatted_COVIDhub-ensemble_{DT}.csv')\n",
    "df_hub = pd.read_csv(fpath)\n",
    "\n",
    "## Join with acs[[fips,pop,state_fips,state_pop,ratio]] ...\n",
    "df = df_tot.merge(df_acs[['Fips','Pop','State_fips','State_pop','Ratio']], on='Fips')\n",
    "\n",
    "## Add on proj_inc_deaths from hub ...\n",
    "df = df.merge(df_hub,on=['State_fips','Date'])\n",
    "\n",
    "## Reorder columns\n",
    "df = df[['Fips','State_fips','Pop','State_pop','Ratio','Date',\n",
    "         'Proj_inc_deaths', 'True_cum_deaths', 'True_inc_deaths']]\n",
    "\n",
    "## Compute naive inc deaths.\n",
    "df['Naive_inc_deaths'] = df.apply(lambda x: x.Proj_inc_deaths * x.Ratio, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7583b6",
   "metadata": {},
   "source": [
    "### <font color=blue> Get cum deaths at t-1 for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b4e6012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3107/3107 [00:02<00:00, 1108.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20241009-144131\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fips</th>\n",
       "      <th>State_fips</th>\n",
       "      <th>Pop</th>\n",
       "      <th>State_pop</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>Date</th>\n",
       "      <th>Proj_inc_deaths</th>\n",
       "      <th>True_cum_deaths</th>\n",
       "      <th>Cum_deaths_tm1</th>\n",
       "      <th>True_inc_deaths</th>\n",
       "      <th>Naive_inc_deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>58239.000</td>\n",
       "      <td>4997675</td>\n",
       "      <td>0.012</td>\n",
       "      <td>20200613</td>\n",
       "      <td>69.730</td>\n",
       "      <td>6.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>58239.000</td>\n",
       "      <td>4997675</td>\n",
       "      <td>0.012</td>\n",
       "      <td>20200620</td>\n",
       "      <td>83.302</td>\n",
       "      <td>9.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>58239.000</td>\n",
       "      <td>4997675</td>\n",
       "      <td>0.012</td>\n",
       "      <td>20200627</td>\n",
       "      <td>68.179</td>\n",
       "      <td>12.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>58239.000</td>\n",
       "      <td>4997675</td>\n",
       "      <td>0.012</td>\n",
       "      <td>20200704</td>\n",
       "      <td>76.239</td>\n",
       "      <td>13.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>58239.000</td>\n",
       "      <td>4997675</td>\n",
       "      <td>0.012</td>\n",
       "      <td>20200711</td>\n",
       "      <td>88.363</td>\n",
       "      <td>15.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309954</th>\n",
       "      <td>56045</td>\n",
       "      <td>56</td>\n",
       "      <td>6891.000</td>\n",
       "      <td>576641</td>\n",
       "      <td>0.012</td>\n",
       "      <td>20220409</td>\n",
       "      <td>8.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309955</th>\n",
       "      <td>56045</td>\n",
       "      <td>56</td>\n",
       "      <td>6891.000</td>\n",
       "      <td>576641</td>\n",
       "      <td>0.012</td>\n",
       "      <td>20220416</td>\n",
       "      <td>5.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309956</th>\n",
       "      <td>56045</td>\n",
       "      <td>56</td>\n",
       "      <td>6891.000</td>\n",
       "      <td>576641</td>\n",
       "      <td>0.012</td>\n",
       "      <td>20220423</td>\n",
       "      <td>4.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309957</th>\n",
       "      <td>56045</td>\n",
       "      <td>56</td>\n",
       "      <td>6891.000</td>\n",
       "      <td>576641</td>\n",
       "      <td>0.012</td>\n",
       "      <td>20220430</td>\n",
       "      <td>4.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309958</th>\n",
       "      <td>56045</td>\n",
       "      <td>56</td>\n",
       "      <td>6891.000</td>\n",
       "      <td>576641</td>\n",
       "      <td>0.012</td>\n",
       "      <td>20220507</td>\n",
       "      <td>4.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309959 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Fips  State_fips       Pop  State_pop  Ratio      Date  \\\n",
       "0        1001           1 58239.000    4997675  0.012  20200613   \n",
       "1        1001           1 58239.000    4997675  0.012  20200620   \n",
       "2        1001           1 58239.000    4997675  0.012  20200627   \n",
       "3        1001           1 58239.000    4997675  0.012  20200704   \n",
       "4        1001           1 58239.000    4997675  0.012  20200711   \n",
       "...       ...         ...       ...        ...    ...       ...   \n",
       "309954  56045          56  6891.000     576641  0.012  20220409   \n",
       "309955  56045          56  6891.000     576641  0.012  20220416   \n",
       "309956  56045          56  6891.000     576641  0.012  20220423   \n",
       "309957  56045          56  6891.000     576641  0.012  20220430   \n",
       "309958  56045          56  6891.000     576641  0.012  20220507   \n",
       "\n",
       "        Proj_inc_deaths  True_cum_deaths  Cum_deaths_tm1  True_inc_deaths  \\\n",
       "0                69.730            6.000             NaN              NaN   \n",
       "1                83.302            9.000           6.000            3.000   \n",
       "2                68.179           12.000           9.000            3.000   \n",
       "3                76.239           13.000          12.000            1.000   \n",
       "4                88.363           15.000          13.000            2.000   \n",
       "...                 ...              ...             ...              ...   \n",
       "309954            8.000           18.000          18.000            0.000   \n",
       "309955            5.000           18.000          18.000            0.000   \n",
       "309956            4.000           18.000          18.000            0.000   \n",
       "309957            4.000           18.000          18.000            0.000   \n",
       "309958            4.000           18.000          18.000            0.000   \n",
       "\n",
       "        Naive_inc_deaths  \n",
       "0                  0.813  \n",
       "1                  0.971  \n",
       "2                  0.795  \n",
       "3                  0.888  \n",
       "4                  1.030  \n",
       "...                  ...  \n",
       "309954             0.096  \n",
       "309955             0.060  \n",
       "309956             0.048  \n",
       "309957             0.048  \n",
       "309958             0.048  \n",
       "\n",
       "[309959 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "fipss = df.Fips.unique()\n",
    "\n",
    "dfs = []\n",
    "for fips in tqdm(fipss):\n",
    "    df_county = df[df.Fips==fips]\n",
    "    df_county.sort_values('Date',inplace=True)\n",
    "    df_county.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    cum_deaths_tm1s = []\n",
    "    \n",
    "    for i in range(len(df_county)):\n",
    "        if i==0:\n",
    "            cum_deaths_tm1 = np.nan\n",
    "        else:\n",
    "            cum_deaths_tm1 = df_county.at[i-1, 'True_cum_deaths']\n",
    "        cum_deaths_tm1s.append(cum_deaths_tm1)\n",
    "        \n",
    "    df_county['Cum_deaths_tm1'] = cum_deaths_tm1s\n",
    "    dfs.append(df_county)\n",
    "                \n",
    "    \n",
    "df_tot = pd.concat(dfs)\n",
    "\n",
    "## Reorder columns \n",
    "df_tot = df_tot[['Fips', 'State_fips', 'Pop', 'State_pop', 'Ratio', 'Date',\n",
    "                 'Proj_inc_deaths', 'True_cum_deaths',  'Cum_deaths_tm1',\n",
    "                 'True_inc_deaths','Naive_inc_deaths']]\n",
    "\n",
    "df_tot.reset_index(inplace=True,drop=True)\n",
    "\n",
    "df = df_tot.copy()\n",
    "\n",
    "## reset index\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "## SAVE CSV!\n",
    "# fpath = os.path.join(DATA_DIR,'processed','scratch', f'processed_naive_deaths_{DT}.csv')\n",
    "fpath = os.path.join(DATA_DIR,'processed', f'processed_naive_deaths_{DT}.csv')\n",
    "\n",
    "df.to_csv(fpath,index=False)\n",
    "print(DT)\n",
    "\n",
    "## READ BACK AND CHECK\n",
    "dff = pd.read_csv(fpath)\n",
    "display(dff)\n",
    "# dff.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c02607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
