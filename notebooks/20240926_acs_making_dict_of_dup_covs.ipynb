{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77a5a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from setup_nb_env import *\n",
    "\n",
    "from epsampling.utils import load_csv\n",
    "# pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "DATA_DIR = '/work/users/k/4/k4thryn/Repos/EpSampling/data/'\n",
    "DT = datetime.today().strftime('%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6102fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = '20240926-122824'\n",
    "\n",
    "fpath = os.path.join(DATA_DIR,'processed',f'formatted_acs_results_{timestamp}.csv')\n",
    "df = pd.read_csv(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cde45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "dup_sets = collections.defaultdict(list)\n",
    "\n",
    "# matched = []\n",
    "for name, ser in df.items():\n",
    "    for name2, ser2 in df.items():\n",
    "        if name==name2:\n",
    "            continue\n",
    "        else:\n",
    "            if ser.equals(ser2):\n",
    "                if len(dup_sets) == 0:\n",
    "                    dup_sets[0] = [name, name2]\n",
    "                    \n",
    "                else:\n",
    "                    for i,dups in dup_sets.items():\n",
    "                        if name in dups:\n",
    "                            dup_sets[i].append(name2)\n",
    "                            dup_sets[i] = list(set(dup_sets[i]))\n",
    "                            break\n",
    "                        elif name2 in dups:\n",
    "                            dup_sets[i].append(name)\n",
    "                            dup_sets[i] = list(set(dup_sets[i]))\n",
    "                            break\n",
    "                    else:\n",
    "                        this_i = len(dup_sets) + 1\n",
    "                        dup_sets[this_i] = [name, name2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f526a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "fpath = \"../constants_and_dicts/acs_duplicate_covs_dict.json\" \n",
    "with open(fpath, 'w') as fp:\n",
    "    json.dump(dup_sets, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afdccb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': ['POP_x13', 'POP_x2', 'POP_x14', 'POP_x3'],\n",
       " '2': ['POP_HISP_x12', 'POP_HISP_x13'],\n",
       " '3': ['HH_x6', 'HU_OCC', 'HH_x5'],\n",
       " '4': ['POP_16p_EMP_x8',\n",
       "  'POP_16p_EMP_x7',\n",
       "  'POP_16p_EMP_x10',\n",
       "  'POP_16p_EMP_x11',\n",
       "  'POP_16p_EMP'],\n",
       " '5': ['IND_CONS_x7', 'IND_CONS_x8'],\n",
       " '6': ['IND_MAN_x7', 'IND_MAN_x8'],\n",
       " '7': ['IND_WHT_x8', 'IND_WHT_x7'],\n",
       " '8': ['IND_RETT_x7', 'IND_RETT_x8'],\n",
       " '9': ['IND_INF_x7', 'IND_INF_x8'],\n",
       " '10': ['IND_OSER_x8', 'IND_OSER_x7'],\n",
       " '11': ['IND_PUBA_x8', 'IND_PUBA_x7'],\n",
       " '12': ['HU_x14', 'HU_x15'],\n",
       " '13': ['OCC_SERV_HCS_x11', 'OCC_SERV_HCS_x12'],\n",
       " '14': ['OCC_SERV_FPS_x12', 'OCC_SERV_FPS_x11'],\n",
       " '15': ['OCC_SERV_BGM_x12', 'OCC_SERV_BGM_x11'],\n",
       " '16': ['OCC_SERV_PCS_x12', 'OCC_SERV_PCS_x11'],\n",
       " '17': ['OCC_SALES_SR_x11', 'OCC_SALES_SR_x12'],\n",
       " '18': ['OCC_SALES_OAS_x11', 'OCC_SALES_OAS_x12'],\n",
       " '19': ['OCC_NRCM_FFF_x12', 'OCC_NRCM_FFF_x11'],\n",
       " '20': ['OCC_NRCM_CE_x12', 'OCC_NRCM_CE_x11'],\n",
       " '21': ['OCC_NRCM_IMR_x11', 'OCC_NRCM_IMR_x12'],\n",
       " '22': ['OCC_PTMM_P_x11', 'OCC_PTMM_P_x12'],\n",
       " '23': ['OCC_PTMM_T_x12', 'OCC_PTMM_T_x11'],\n",
       " '24': ['OCC_PTMM_MM_x12', 'OCC_PTMM_MM_x11']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "fpath = \"../constants_and_dicts/acs_duplicate_covs_dict.json\" \n",
    "with open(fpath, 'r') as json_file:\n",
    "    dupss = json.load(json_file)\n",
    "display(dupss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a417433c",
   "metadata": {},
   "source": [
    "## <font color=red> NEXT ToDo: \n",
    "    1) curate the acs data. just remove dups. don't need dictionary.\n",
    "    2) get naive deaths and finish out data curation pipeline \n",
    "        ... remember to use inc for prediction target and cums as a covariate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collections\n",
    "# dup_dict = collections.defaultdict(list)\n",
    "\n",
    "# matched = []\n",
    "# for name, ser in df.items():\n",
    "#     for name2, ser2 in df.items():\n",
    "#         if name==name2:\n",
    "#             break\n",
    "#         else:\n",
    "#             if ser.equals(ser2):\n",
    "#                 if name not in matched:\n",
    "#                     dup_dict[name].append(name2)\n",
    "#                     matched.append(name)\n",
    "#                 elif name2 not in matched:\n",
    "                \n",
    "                \n",
    "#                 if (name2 in matched) or (name in matched):\n",
    "#                     continue\n",
    "                    \n",
    "                    \n",
    "#                 else:\n",
    "#                     dup_dict[name].append(name2)\n",
    "#                     matched.append(name2)\n",
    "#                     matched.append(name)\n",
    "# #                 if name not in dup_dict.keys():\n",
    "# #                     dup_dict[name] = [name2]\n",
    "# #                 else:\n",
    "# #                     dup_dict[name].append(name2)\n",
    "                    \n",
    "# import json\n",
    "# fpath = \"../constants_and_dicts/_____acs_duplicate_covs_dict.json\" \n",
    "# with open(fpath, 'w') as fp:\n",
    "#     json.dump(dup_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3df6980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import collections\n",
    "# dup_dict = collections.defaultdict(list)\n",
    "\n",
    "# matched = []\n",
    "# for name, ser in df.items():\n",
    "#     for name2, ser2 in df.items():\n",
    "#         if name==name2:\n",
    "#             break\n",
    "#         else:\n",
    "#             if ser.equals(ser2):\n",
    "#                 if name not in matched:\n",
    "#                     dup_dict[name].append(name2)\n",
    "#                     matched.append(name)\n",
    "#                 elif name2 not in matched:\n",
    "                \n",
    "                \n",
    "#                 if (name2 in matched) or (name in matched):\n",
    "#                     continue\n",
    "                    \n",
    "                    \n",
    "#                 else:\n",
    "#                     dup_dict[name].append(name2)\n",
    "#                     matched.append(name2)\n",
    "#                     matched.append(name)\n",
    "# #                 if name not in dup_dict.keys():\n",
    "# #                     dup_dict[name] = [name2]\n",
    "# #                 else:\n",
    "# #                     dup_dict[name].append(name2)\n",
    "                    \n",
    "# import json\n",
    "# fpath = \"../constants_and_dicts/NEW_acs_duplicate_covs_dict.json\" \n",
    "# with open(fpath, 'w') as fp:\n",
    "#     json.dump(dup_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "889b3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# fpath = \"../constants_and_dicts/acs_duplicate_covs_dict.json\" \n",
    "# with open(fpath, 'r') as json_file:\n",
    "#     acs_dups = json.load(json_file)\n",
    "# display(acs_dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a80eecfc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# fpath = \"../constants_and_dicts/OLD_acs_duplicate_covs_dict.json\" \n",
    "# with open(fpath, 'r') as json_file:\n",
    "#     acs_dups = json.load(json_file)\n",
    "# display(acs_dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d26bd1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Remove duplicates according to dup dict ... \n",
    "\n",
    "# to_drop = []\n",
    "# for k,v in acs_dups:\n",
    "# acs_dups.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dee0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('..raw_data/county_covariates.json') as f:\n",
    "#     d = json.load(f)\n",
    "\n",
    "# county_covs = []\n",
    "# for entry in d:\n",
    "#     county_covs.append(entry)\n",
    "\n",
    "# df_pop = pd.DataFrame(columns=['Postal','Fips','Pop'])\n",
    "\n",
    "# for idx in range(len(county_covs)):\n",
    "#     pop = county_covs[idx]['population']['2019']\n",
    "#     fips = county_covs[idx]['fips']\n",
    "#     state = county_covs[idx]['state']\n",
    "#     df_pop.loc[idx] = pd.Series({'Postal':state, 'Fips':str(fips), 'Pop':pop})\n",
    "    \n",
    "    \n",
    "# state_fips = pd.read_csv('constants/state_fips.csv')\n",
    "\n",
    "# df_pop = df_pop.merge(state_fips, on='Postal')\n",
    "# df_pop.drop('FIPS',inplace=True,axis=1)\n",
    "# df_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a0799d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
