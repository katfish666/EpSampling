{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d579487",
   "metadata": {},
   "source": [
    "## [Using virtual enviroments in jupyter on longleaf](https://help.rc.unc.edu/python-packages/#using-virtual-environments-in-a-jupyter-notebook)\n",
    "\n",
    "\n",
    "I ran that command for `py310` and `base` conda environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623a14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../epsampling/')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    " \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(suppress=True,formatter={'float_kind': '{:f}'.format})\n",
    "    \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "DATA_DIR = '/work/users/k/4/k4thryn/Repos/EpSampling/data/'\n",
    "DT = datetime.today().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "from IPython.display import Audio\n",
    "def meow():\n",
    "    display(Audio(filename='../cat_meow2.wav', autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93b07e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "timestamp = '20241029-123405'\n",
    "fpath = os.path.join(DATA_DIR,'cached', f'df_modeling_pastweeks_{timestamp}.csv')\n",
    "\n",
    "df = pd.read_csv(fpath)\n",
    "\n",
    "## add dummy state variable\n",
    "df_fips = pd.read_csv('state_fips.csv')\n",
    "fips_to_st = {k:v for k,v in zip(df_fips.Fips, df_fips.Postal)}\n",
    "dummies = pd.get_dummies(df['State_fips']).rename(columns=lambda x: 'Is_' + fips_to_st[x]  )\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "df.drop(['State_fips'], inplace=True, axis=1)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "## remove outliers\n",
    "from scipy import stats\n",
    "df = df[np.abs(stats.zscore(df.Target)) < 5]\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # #\n",
    "# # # # # # # # # # # # # # # # # # # # #\n",
    "df = df.sample(10000)\n",
    "# # # # # # # # # # # # # # # # # # # # #\n",
    "# # # # # # # # # # # # # # # # # # # # #\n",
    "\n",
    "## separate X and y\n",
    "not_feats = ['Target','Fips', 'State_fips', 'Date',\n",
    "             'Proj_inc_deaths', 'True_cum_deaths', 'Cum_deaths_tm1',\n",
    "             'True_inc_deaths', 'Naive_inc_deaths','Target']\n",
    "feats = [x for x in df.columns if x not in not_feats]\n",
    "df_X = df[feats]\n",
    "# .values.astype('float32')\n",
    "df_y = df['Target']\n",
    "\n",
    "# .values.astype('float32')\n",
    "\n",
    "# standardize X\n",
    "# df_X = (df_X-df_X.mean()) / df_X.std()\n",
    "\n",
    "_df_X = df_X.loc[:, df_X.columns != 'Naive']\n",
    "_df_X = (_df_X-_df_X.mean()) / _df_X.std()\n",
    "_df_X['Naive'] = df_X['Naive']\n",
    "df_X = _df_X\n",
    "\n",
    "\n",
    "\n",
    "#     X_arr = df[feat_cols].values.astype('float32')\n",
    "#     y_arr = df[target_col].values.astype('float32')\n",
    "#     X = torch.tensor(X_arr)\n",
    "#     y = torch.tensor(y_arr).reshape(-1, 1)\n",
    "\n",
    "# Random split\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.1, \n",
    "                                                      random_state=666, shuffle=True)\n",
    "\n",
    "X_test = torch.tensor( df_test.values.astype('float32'))\n",
    "y_test = torch.tensor( y_test.values.astype('float32')).reshape(-1, 1)\n",
    "X_train = torch.tensor( df_train.values.astype('float32'))\n",
    "y_train = torch.tensor( y_train.values.astype('float32')).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c377fe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test['Naive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b4e4b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1b834e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pop</th>\n",
       "      <th>State_pop</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>TPOP</th>\n",
       "      <th>POPDEN</th>\n",
       "      <th>Metro</th>\n",
       "      <th>Micro</th>\n",
       "      <th>POP1</th>\n",
       "      <th>POP2</th>\n",
       "      <th>POP3</th>\n",
       "      <th>...</th>\n",
       "      <th>Is_TN</th>\n",
       "      <th>Is_TX</th>\n",
       "      <th>Is_UT</th>\n",
       "      <th>Is_VT</th>\n",
       "      <th>Is_VA</th>\n",
       "      <th>Is_WA</th>\n",
       "      <th>Is_WV</th>\n",
       "      <th>Is_WI</th>\n",
       "      <th>Is_WY</th>\n",
       "      <th>Naive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75610</th>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.686</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-1.002</td>\n",
       "      <td>1.099</td>\n",
       "      <td>0.221</td>\n",
       "      <td>-0.746</td>\n",
       "      <td>0.211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>8.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114435</th>\n",
       "      <td>-0.201</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.998</td>\n",
       "      <td>-0.909</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>3.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188334</th>\n",
       "      <td>0.108</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.998</td>\n",
       "      <td>-0.909</td>\n",
       "      <td>1.414</td>\n",
       "      <td>0.359</td>\n",
       "      <td>-0.914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>5.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271047</th>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.679</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>-1.002</td>\n",
       "      <td>1.099</td>\n",
       "      <td>2.418</td>\n",
       "      <td>1.393</td>\n",
       "      <td>-2.635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>10.674</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>1.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12429</th>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.706</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-1.002</td>\n",
       "      <td>1.099</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.833</td>\n",
       "      <td>-0.551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>3.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183940</th>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.998</td>\n",
       "      <td>-0.909</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.091</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>3.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116067</th>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-1.002</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.293</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.783</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>1.343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181095</th>\n",
       "      <td>0.202</td>\n",
       "      <td>1.310</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-1.002</td>\n",
       "      <td>1.099</td>\n",
       "      <td>-0.768</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>1.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106431</th>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.511</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>0.998</td>\n",
       "      <td>-0.909</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>9.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5172</th>\n",
       "      <td>-0.268</td>\n",
       "      <td>-0.471</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-0.238</td>\n",
       "      <td>0.998</td>\n",
       "      <td>-0.909</td>\n",
       "      <td>1.610</td>\n",
       "      <td>-1.586</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>12.512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows Ã— 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pop  State_pop  Ratio   TPOP  POPDEN  Metro  Micro   POP1   POP2  \\\n",
       "75610  -0.235     -0.686 -0.229 -0.233  -0.212 -1.002  1.099  0.221 -0.746   \n",
       "114435 -0.201     -0.336 -0.257 -0.198  -0.136  0.998 -0.909  0.161  0.339   \n",
       "188334  0.108      0.162 -0.037  0.103   0.156  0.998 -0.909  1.414  0.359   \n",
       "271047 -0.098     -0.679  0.159 -0.110  -0.242 -1.002  1.099  2.418  1.393   \n",
       "12429  -0.175     -0.706 -0.036 -0.169  -0.174 -1.002  1.099  0.187  0.833   \n",
       "...       ...        ...    ...    ...     ...    ...    ...    ...    ...   \n",
       "183940 -0.023      0.162 -0.154 -0.022  -0.015  0.998 -0.909  0.097 -0.064   \n",
       "116067 -0.011     -0.336  0.027 -0.009   0.054 -1.002  1.099  1.293 -0.232   \n",
       "181095  0.202      1.310 -0.166  0.203  -0.075 -1.002  1.099 -0.768  0.350   \n",
       "106431 -0.233     -0.511 -0.278 -0.226  -0.181  0.998 -0.909  0.095  0.231   \n",
       "5172   -0.268     -0.471 -0.349 -0.262  -0.238  0.998 -0.909  1.610 -1.586   \n",
       "\n",
       "         POP3  ...  Is_TN  Is_TX  Is_UT  Is_VT  Is_VA  Is_WA  Is_WV  Is_WI  \\\n",
       "75610   0.211  ... -0.178 -0.292 -0.094 -0.067 -0.223 -0.111 -0.137 -0.151   \n",
       "114435  0.230  ... -0.178 -0.292 -0.094 -0.067 -0.223 -0.111 -0.137 -0.151   \n",
       "188334 -0.914  ... -0.178 -0.292 -0.094 -0.067 -0.223 -0.111 -0.137 -0.151   \n",
       "271047 -2.635  ... -0.178 -0.292 10.674 -0.067 -0.223 -0.111 -0.137 -0.151   \n",
       "12429  -0.551  ... -0.178 -0.292 -0.094 -0.067 -0.223 -0.111 -0.137 -0.151   \n",
       "...       ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "183940  0.091  ... -0.178 -0.292 -0.094 -0.067 -0.223 -0.111 -0.137 -0.151   \n",
       "116067 -0.783  ... -0.178 -0.292 -0.094 -0.067 -0.223 -0.111 -0.137 -0.151   \n",
       "181095  0.841  ... -0.178 -0.292 -0.094 -0.067 -0.223 -0.111 -0.137 -0.151   \n",
       "106431  0.184  ... -0.178 -0.292 -0.094 -0.067 -0.223 -0.111 -0.137 -0.151   \n",
       "5172   -0.845  ... -0.178 -0.292 -0.094 -0.067 -0.223 -0.111 -0.137 -0.151   \n",
       "\n",
       "        Is_WY  Naive  \n",
       "75610  -0.095  8.624  \n",
       "114435 -0.095  3.481  \n",
       "188334 -0.095  5.222  \n",
       "271047 -0.095  1.556  \n",
       "12429  -0.095  3.164  \n",
       "...       ...    ...  \n",
       "183940 -0.095  3.259  \n",
       "116067 -0.095  1.343  \n",
       "181095 -0.095  1.122  \n",
       "106431 -0.095  9.554  \n",
       "5172   -0.095 12.512  \n",
       "\n",
       "[9000 rows x 115 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d182c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "def get_loader(X, y,  bs=32):\n",
    "    \n",
    "#     if isinstance(X, pd.DataFrame):\n",
    "#     X = X.values.astype('float32')\n",
    "#     else:\n",
    "#         X = X.astype('float32')\n",
    "#     y = y.values.astype('float32')\n",
    "#     X = torch.tensor(X)\n",
    "#     y = torch.tensor(y).reshape(-1, 1)\n",
    "    \n",
    "    dataset = data_utils.TensorDataset(X, y)\n",
    "    loader = data_utils.DataLoader(dataset, batch_size=bs, shuffle=True, drop_last=True)\n",
    "    \n",
    "    return loader   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d722d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "num_feats = len(feats)\n",
    "print(num_feats)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class EpModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.l0 = nn.Linear(num_feats, 128)\n",
    "        self.l1 = nn.Linear(128, 64)\n",
    "        self.l2 = nn.Linear(64, 32)\n",
    "        self.out = nn.Linear(32, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.l0( x ))\n",
    "        x = self.relu(self.l1( x ))\n",
    "        x = self.relu(self.l2( x ))\n",
    "#         x = self.relu(self.out( x ))\n",
    "        x = self.out( x )\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c083ba7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea93546ba9e4a99b3f0834e56ec5344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429.7286682128906 347.89080810546875\n",
      "70.15271759033203 59.11619567871094\n",
      "68.32462310791016 59.764434814453125\n",
      "65.78218841552734 61.37718963623047\n",
      "63.385459899902344 63.427345275878906\n",
      "58.79307556152344 65.45928192138672\n",
      "53.9105224609375 69.55192565917969\n",
      "48.5062141418457 76.48306274414062\n",
      "42.908634185791016 85.11296844482422\n",
      "38.698387145996094 88.21636199951172\n",
      "MSE: 58.59\n",
      "RMSE: 7.65\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "n_epochs = 100  \n",
    "bs = 512\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "test_history = []\n",
    "train_history = []\n",
    "\n",
    "model = EpModel()\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    \n",
    "    loader = get_loader(X_train, y_train, bs=bs)\n",
    "    for X_batch, y_batch in loader:\n",
    "    \n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    y_pred = model(X_train)\n",
    "    train_mse = float(loss_fn(y_pred, y_train))\n",
    "    train_history.append(train_mse) \n",
    "    \n",
    "    y_pred = model(X_test)\n",
    "    test_mse = float(loss_fn(y_pred, y_test))\n",
    "    test_history.append(test_mse)\n",
    "    \n",
    "    \n",
    "    if test_mse < best_mse:\n",
    "        best_mse = test_mse\n",
    "        best_weights = copy.deepcopy(model.state_dict()) \n",
    "        \n",
    "    if epoch % 10==0: print(train_mse, test_mse)\n",
    "            \n",
    "# model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(test_history)\n",
    "plt.plot(train_history)\n",
    "# plt.yscale('log')\n",
    "plt.show()            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e8d93b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLP': {'MAE': 4.9082017,\n",
       "  'MedAE': 2.3774266,\n",
       "  'MSE': 99.203156,\n",
       "  'RMSE': 9.960078,\n",
       "  'r2': 0.6203679099728538},\n",
       " 'Naive': {'MAE': 3.699807102455956,\n",
       "  'MedAE': 1.798351844602034,\n",
       "  'MSE': 59.614086524504806,\n",
       "  'RMSE': 7.721015899770237,\n",
       "  'r2': 0.7718679318678543}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'MLP': {'MAE': 3.265312,\n",
       "  'MedAE': 1.8400893,\n",
       "  'MSE': 36.67691,\n",
       "  'RMSE': 6.0561466,\n",
       "  'r2': 0.8952505951547168},\n",
       " 'Naive': {'MAE': 3.765331180428061,\n",
       "  'MedAE': 1.8556009876412158,\n",
       "  'MSE': 74.09662575929796,\n",
       "  'RMSE': 8.607939693056519,\n",
       "  'r2': 0.7883797494358675}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    "def get_performance(model_names, model_preds, y_test):\n",
    "    \n",
    "    metrics_dict = {'MAE': mean_absolute_error,\n",
    "                    'MedAE': median_absolute_error,\n",
    "                    'MSE': mean_squared_error,\n",
    "                    'RMSE': mean_squared_error,\n",
    "                    'r2': r2_score,\n",
    "                   }\n",
    "\n",
    "    model_res_dict = {model:{} for model in model_names}\n",
    "    \n",
    "    for model,pred in zip(model_names, model_preds):\n",
    "        for metric, func in metrics_dict.items():\n",
    "            if metric=='RMSE':\n",
    "                model_res_dict[model][metric] = func(y_test, pred, squared=False)\n",
    "            else:\n",
    "                model_res_dict[model][metric] = func(y_test, pred)\n",
    "            \n",
    "    return model_res_dict\n",
    "\n",
    "\n",
    "metrics_dict = get_performance(['MLP','Naive'], \n",
    "                               [model(X_test).detach().numpy(), df_test['Naive'].values], \n",
    "                               y_test)\n",
    "display(metrics_dict)\n",
    "\n",
    "metrics_dict = get_performance(['MLP','Naive'], \n",
    "                               [model(X_train).detach().numpy(), df_train['Naive'].values], \n",
    "                               y_train)\n",
    "display(metrics_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b0488f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "# np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03361706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def line_plot(df, x_col, y_col, title=None):\n",
    "\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import seaborn as sns\n",
    "\n",
    "#     sns.regplot(data=df, x=x_col, y=y_col, \n",
    "#                 scatter_kws={'s':10, 'alpha':0.5}, \n",
    "#                 line_kws={'color':'k','linewidth':0.5},logx=False)\n",
    "    \n",
    "#     if title is not None:\n",
    "#         plt.title(title) \n",
    "\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# df_test['NN'] = y_pred.detach().numpy()\n",
    "# line_plot(df_test, 'Target', 'NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699c2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a7d96d5",
   "metadata": {},
   "source": [
    "# from epsampling.utils import get_chunks\n",
    "# chunks = get_chunks(list(df.Date.unique()), num_membs=2)\n",
    "\n",
    "# Random split\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=666, shuffle=True)\n",
    "\n",
    "\n",
    "# X_train = df_train[feats].values.astype('float32')\n",
    "# y_train = df_train['Target'].values.astype('float32')\n",
    "\n",
    "X_test = df_test[feats].values.astype('float32')\n",
    "y_test = df_test['Target'].values.astype('float32')\n",
    "\n",
    "# # Convert to 2D PyTorch tensors\n",
    "# X_train = torch.tensor(X_train)\n",
    "# y_train = torch.tensor(y_train).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test)\n",
    "y_test = torch.tensor(y_test).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# def standardize_vector(vector):\n",
    "#     mean = torch.mean(vector)\n",
    "#     std = torch.std(vector)\n",
    "#     return (vector - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81af1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.utils.data as data_utils\n",
    "\n",
    "# def get_df_loader(df, feat_cols, target_col='Target', bs=32):\n",
    "    \n",
    "#     X_arr = df[feat_cols].values.astype('float32')\n",
    "#     y_arr = df[target_col].values.astype('float32')\n",
    "#     X = torch.tensor(X_arr)\n",
    "#     y = torch.tensor(y_arr).reshape(-1, 1)\n",
    "    \n",
    "#     dataset = data_utils.TensorDataset(X, y)\n",
    "#     loader = data_utils.DataLoader(dataset, batch_size=bs, shuffle=True, drop_last=True)\n",
    "    \n",
    "#     return loader   \n",
    "\n",
    "\n",
    "# import torch.utils.data as data_utils\n",
    "\n",
    "# def get_loader(X, feat_cols, target_col='Target', bs=32):\n",
    "    \n",
    "#     X_arr = df[feat_cols].values.astype('float32')\n",
    "#     y_arr = df[target_col].values.astype('float32')\n",
    "#     X = torch.tensor(X_arr)\n",
    "#     y = torch.tensor(y_arr).reshape(-1, 1)\n",
    "    \n",
    "#     dataset = data_utils.TensorDataset(X, y)\n",
    "#     loader = data_utils.DataLoader(dataset, batch_size=bs, shuffle=True, drop_last=True)\n",
    "    \n",
    "#     return loader   \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c324b6c9",
   "metadata": {},
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "num_feats = len(feats)\n",
    "print(num_feats)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class EpModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.l0 = nn.Linear(num_feats, 128)\n",
    "        self.l1 = nn.Linear(128, 64)\n",
    "        self.l2 = nn.Linear(64, 32)\n",
    "        self.out = nn.Linear(32, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.l0( x ))\n",
    "        x = self.relu(self.l1( x ))\n",
    "        x = self.relu(self.l2( x ))\n",
    "#         x = self.relu(self.out( x ))\n",
    "        x = self.out( x )\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33f6b029",
   "metadata": {},
   "source": [
    "import copy\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "n_epochs = 100  \n",
    "bs = 512\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    "\n",
    "model = EpModel()\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    \n",
    "    loader = get_loader(df_train, feats, 'Target', bs=bs)\n",
    "    for X_batch, y_batch in loader:\n",
    "    \n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())  \n",
    "    print(mse)\n",
    "            \n",
    "# model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "# plt.yscale('log')\n",
    "plt.show()            \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fce69858",
   "metadata": {},
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    "def get_performance(model_names, model_preds, y_test):\n",
    "    \n",
    "    metrics_dict = {'MAE': mean_absolute_error,\n",
    "                    'MedAE': median_absolute_error,\n",
    "                    'MSE': mean_squared_error,\n",
    "                    'RMSE': mean_squared_error,\n",
    "                    'r2': r2_score,\n",
    "#                     'relMAE': mean_relative_absolute_error,\n",
    "#                     'relMedAE': median_relative_absolute_error\n",
    "                   }\n",
    "\n",
    "    model_res_dict = {model:{} for model in model_names}\n",
    "    \n",
    "    for model,pred in zip(model_names, model_preds):\n",
    "        for metric, func in metrics_dict.items():\n",
    "#             if metric=='relMAE':\n",
    "#                 model_res_dict[model][metric] = func(y_test, pred, y_pred_benchmark=y_naive)\n",
    "#             elif metric=='relMedAE':\n",
    "#                 model_res_dict[model][metric] = func(y_test, pred, y_pred_benchmark=y_naive)\n",
    "            if metric=='RMSE':\n",
    "                model_res_dict[model][metric] = func(y_test, pred, squared=False)\n",
    "            else:\n",
    "                model_res_dict[model][metric] = func(y_test, pred)\n",
    "            \n",
    "    return model_res_dict\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03ab8ac8",
   "metadata": {},
   "source": [
    "# from epsampling.modeling import get_performance\n",
    "metrics_dict = get_performance(['Model'], [y_pred.detach().numpy()], y_test)\n",
    "\n",
    "def line_plot(df, x_col, y_col, title=None):\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    sns.regplot(data=df, x=x_col, y=y_col, \n",
    "                scatter_kws={'s':10, 'alpha':0.5}, \n",
    "                line_kws={'color':'k','linewidth':0.5},logx=False)\n",
    "    \n",
    "    if title is not None:\n",
    "        plt.title(title) \n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "print(metrics_dict)\n",
    "\n",
    "\n",
    "df_test['NN'] = y_pred.detach().numpy()\n",
    "line_plot(df_test, 'Target', 'NN')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff9b7bf7",
   "metadata": {},
   "source": [
    "plt.plot(history)\n",
    "plt.yscale('log')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9be3ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb88aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150fa3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a1ba53f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import copy\n",
    " \n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# # from tqdm.notebook import tqdm\n",
    "\n",
    "# n_epochs = 100  \n",
    "# bs = 512\n",
    "\n",
    "# batch_start = torch.arange(0, len(X_train), bs)\n",
    " \n",
    "# # Hold the best model\n",
    "# best_mse = np.inf   # init to infinity\n",
    "# best_weights = None\n",
    "# history = []\n",
    " \n",
    "# for epoch in range(n_epochs):\n",
    "#     model.train()\n",
    "#     with tqdm(batch_start) as bar:\n",
    "# #         bar.set_description(f\"Epoch {epoch}\")\n",
    "#         for start in bar:\n",
    "#             # take a batch\n",
    "#             X_batch = X_train[start:start+bs]\n",
    "#             y_batch = y_train[start:start+bs]\n",
    "#             # forward pass\n",
    "#             y_pred = model(X_batch)\n",
    "#             loss = loss_fn(y_pred, y_batch)\n",
    "#             # backward pass\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             # update weights\n",
    "#             optimizer.step()\n",
    "#             # print progress\n",
    "#             bar.set_postfix(mse=float(loss))\n",
    "#     # evaluate accuracy at end of each epoch\n",
    "#     model.eval()\n",
    "#     y_pred = model(X_test)\n",
    "#     mse = loss_fn(y_pred, y_test)\n",
    "#     mse = float(mse)\n",
    "#     history.append(mse)\n",
    "#     if mse < best_mse:\n",
    "#         best_mse = mse\n",
    "#         best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# # model.load_state_dict(best_weights)\n",
    "# print(\"MSE: %.2f\" % best_mse)\n",
    "# print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "# plt.plot(history)\n",
    "# # plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d447b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b2e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ecfae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c12468",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytest",
   "language": "python",
   "name": "pytest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
