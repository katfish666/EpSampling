{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b38a7d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from setup_nb_env import *\n",
    "\n",
    "from epsampling.utils import load_csv\n",
    "# pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "DATA_DIR = '/work/users/k/4/k4thryn/Repos/EpSampling/data/'\n",
    "DT = datetime.today().strftime('%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "630cc06a",
   "metadata": {},
   "source": [
    "#### _Which csv files do i need?_\n",
    "- state_fips\n",
    "- nytimes true county deaths\n",
    "- covidhub predicted state deaths\n",
    "- acs census covariates"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2c1390e",
   "metadata": {},
   "source": [
    "#### _Order of operations?_\n",
    "1. normalize column names (and types) for each!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c01b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## df = pd.read_csv('../constants/state_fips.csv')\n",
    "## df.rename({'FIPS':'Fips'},axis=1,inplace=True)\n",
    "## df.to_csv('state_fips.csv',index=False)\n",
    "\n",
    "# df = pd.read_csv('state_fips.csv',index_col='Fips')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d51d6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm \n\u001b[0;32m----> 9\u001b[0m my_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mdata_dir\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOVIDhub-ensemble\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmy_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/*.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m types \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoint\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "## COVID HUB ENSEMBLE STATE PREDICTIONS ############\n",
    "#####################################################\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "my_dir = os.path.join(data_dir,'raw','COVIDhub-ensemble')\n",
    "files = glob.glob(f'{my_dir}/*.csv')\n",
    "\n",
    "types = ['point']\n",
    "targets = ['1 wk ahead inc death']\n",
    "\n",
    "all_dfs = []\n",
    "for f in tqdm(files,total=len(files)):\n",
    "    df = pd.read_csv(f)\n",
    "    ## Choose which types (only point for now)\n",
    "    df = df[df.type=='point']\n",
    "    ## Only 1 wk ahead inc\n",
    "    df = df[df.target.isin(targets)]\n",
    "    all_dfs.append(df)\n",
    "df_all = pd.concat(all_dfs)\n",
    "\n",
    "## REFORMAT dataframe ...\n",
    "## choose cols\n",
    "df = df_all[['location','target_end_date','value']]\n",
    "## rename cols\n",
    "df.rename({'location':'Fips',\n",
    "           'target_end_date':'Date',\n",
    "           'value':'Pred_state_deaths'}, axis=1, inplace=True)\n",
    "## dtype check: good\n",
    "\n",
    "## SAVE CSV!\n",
    "fpath = os.path.join(DATA_DIR,'processed',f'formatted_COVIDhub-ensemble_{DT}.csv')\n",
    "df.to_csv(fpath,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071a0619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "## NYT TRUE COUNTY DEATHS ###########################\n",
    "#####################################################\n",
    "\n",
    "fpath = os.path.join(data_dir,'raw','nytimes','us-counties.csv')\n",
    "df = pd.read_csv(fpath)\n",
    "## drop nans lmao.\n",
    "if df.isnull().values.any()==True:\n",
    "    print('Dropped NaNs!')\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "## capitalize cols.\n",
    "df.columns = df.columns.str.capitalize()\n",
    "\n",
    "## IMPORTANT: pull out samples from 'nytimes' that have matched dates to 'COVIDhub-ensemble' ...\n",
    "df_hub,_ = load_csv('formatted_COVIDhub-ensemble')\n",
    "my_dates = df_hub.Date.unique().tolist()\n",
    "df = df[df.Date.isin(my_dates)]\n",
    "\n",
    "## REFORMAT dataframe ...\n",
    "## choose cols\n",
    "df = df[['Date','Fips','Deaths']]\n",
    "## rename cols\n",
    "df.rename({'Deaths':'True_county_deaths'},axis=1,inplace=True)\n",
    "## fix dtypes\n",
    "df['Fips'] = df.Fips.astype('int64').astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1601f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVE CSV!\n",
    "fpath = os.path.join(DATA_DIR,'processed',f'formatted_nytimes-us-counties_{DT}.csv')\n",
    "df.to_csv(fpath,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9574d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad142568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c343b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7962447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
