{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656f3132",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from setup_nb_env import *\n",
    "\n",
    "data_dir = '/work/users/k/4/k4thryn/Repos/EpSampling/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e7313c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Make df per state: 100%|██████████| 53/53 [00:07<00:00,  7.55it/s]\n",
      "Compute naive deaths: 100%|██████████| 53/53 [00:03<00:00, 13.40it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from epsampling.utils import load_latest_csv\n",
    "\n",
    "#############################################\n",
    "### Get state COVIDhub-ensemble predictions\n",
    "#############################################\n",
    "\n",
    "## Get fips\n",
    "state_to_fips = pd.read_csv('../constants/state_fips.csv')\n",
    "state_to_fips.rename({'FIPS':'State_fips'},axis=1,inplace=True)\n",
    "\n",
    "## Add fips to forecast table.\n",
    "df,_ = load_latest_csv('covidhub_ensemble_1wkcum_point')\n",
    "df.columns = df.columns.str.capitalize()\n",
    "df.rename({'Location':'State_fips'},axis=1,inplace=True)\n",
    "\n",
    "df = df.merge(state_to_fips, on='State_fips')\n",
    "\n",
    "## Remove and rename columns ...\n",
    "df_states = df.drop(['Target','Forecast_date'], axis=1, errors='ignore')\n",
    "df_states.rename({'Target_end_date':'Date', 'Value':'COVIDhubEns_state_deaths'}, axis=1, inplace=True)\n",
    "# df_states\n",
    "\n",
    "\n",
    "#############################################\n",
    "### Get ground truth covid deaths per county.\n",
    "#############################################\n",
    "\n",
    "df_counties = pd.read_csv(f'{data_dir}nytimes/us-counties.csv')\n",
    "df_counties.columns = df_counties.columns.str.capitalize()\n",
    "df_counties.drop(['Cases'],axis=1,inplace=True)\n",
    "df_counties.dropna(inplace=True)\n",
    "\n",
    "## Make list of dfs because everything in one df is too big.\n",
    "forecast_dates = list(df_states.Date.unique())\n",
    "all_states = list(df_counties.State.unique())\n",
    "\n",
    "state_dfs = {}\n",
    "\n",
    "for state in tqdm(all_states, total=len(all_states), desc='Make df per state'):\n",
    "#     if state in ['Virgin Islands','Northern Mariana Islands']:\n",
    "#         continue\n",
    "    df = df_counties[df_counties.State==state]\n",
    "    df['Fips'] = df['Fips'].astype('int64').astype('str')\n",
    "    ## Only need dates for counties that we have for states ... \n",
    "    df = df[df.Date.isin(forecast_dates)]\n",
    "    state_dfs[state] = df\n",
    "    \n",
    "    \n",
    "#############################################\n",
    "### Get pop ratios for each county.\n",
    "#############################################\n",
    "\n",
    "df_pop,_ = load_latest_csv('pop_ratios_per_county',f'{data_dir}processed/')\n",
    "df_pop['Fips'] = df_pop['Fips'].astype('int64').astype('str')\n",
    "df_pop = df_pop[['Postal','Fips', 'Pop', 'State', 'Pop_ratio']]\n",
    "\n",
    "for state,df in state_dfs.items():\n",
    "    df_state_pop = df_pop[df_pop.State==state]    \n",
    "    df = df.merge(df_state_pop, on=['Fips','State'])\n",
    "    state_dfs[state] = df\n",
    "\n",
    "\n",
    "#############################################\n",
    "### Compute naive deaths for each county.\n",
    "#############################################\n",
    "\n",
    "merged_dfs = {}\n",
    "for state in tqdm(state_dfs.keys(), total=len(state_dfs), desc='Compute naive deaths'):\n",
    "    \n",
    "    df_state = df_states[df_states.State==state]\n",
    "    df_counties = state_dfs[state]\n",
    "    \n",
    "#     print(df_state.columns, df_counties.columns)\n",
    "#     display(df_counties, df_state)\n",
    "    df_merged = df_counties.merge(df_state, on=['Date','State','Postal'])\n",
    "    df_merged.rename({'Deaths':'True_county_deaths'}, axis=1, inplace=True)\n",
    "    \n",
    "    df_merged['Naive_county_deaths'] = df_merged.apply(lambda x: x.Pop_ratio * x.COVIDhubEns_state_deaths, \n",
    "                                                       axis=1)\n",
    "    \n",
    "    df_merged = df_merged[['State_fips','State','Postal','County','Fips','Date','COVIDhubEns_state_deaths',\n",
    "                           'Pop','Pop_ratio','True_county_deaths',\n",
    "                           'Naive_county_deaths']]\n",
    "    merged_dfs[state] = df_merged\n",
    "    \n",
    "    \n",
    "#############################################    \n",
    "### Save dataframe.\n",
    "#############################################    \n",
    "\n",
    "final_df = pd.concat(merged_dfs.values())\n",
    "\n",
    "data_dir = '/work/users/k/4/k4thryn/Repos/EpSampling/data/'\n",
    "d = datetime.today().strftime('%Y%m%d-%H%M%S')\n",
    "final_df.to_csv(f'{data_dir}naive_deaths_all_counties_{d}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d56e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e244159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd1cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
